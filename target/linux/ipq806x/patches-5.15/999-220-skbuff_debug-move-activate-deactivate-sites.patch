From a175a33fb266c02282f60bbe8f0ed72cb00f2f1f Mon Sep 17 00:00:00 2001
From: Tian Yang <tiany@codeaurora.org>
Date: Tue, 29 Dec 2015 13:02:21 -0600
Subject: [PATCH] skbuff_debug: move activate/deactivate sites

This way we can see if next/prev in SKB was changed
while the SKB was not being used.

Change-Id: I281267e230d3406181a07d095a76ae6bc58e2c8d
Signed-off-by: Matthew McClintock <mmcclint@codeaurora.org>
Signed-off-by: Casey Chen <kexinc@codeaurora.org>
---
 net/core/skbuff.c         |  8 +++++---
 net/core/skbuff_recycle.c | 23 +++++++++++++++++------
 2 files changed, 22 insertions(+), 9 deletions(-)

--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -246,6 +246,7 @@ struct sk_buff *__build_skb(void *data,
 	skb = kmem_cache_alloc(skbuff_head_cache, GFP_ATOMIC);
 	if (unlikely(!skb))
 		return NULL;
+	skbuff_debugobj_init_and_activate(skb);
 
 	memset(skb, 0, offsetof(struct sk_buff, tail));
 	__build_skb_around(skb, data, frag_size);
@@ -420,6 +421,7 @@ struct sk_buff *__alloc_skb(unsigned int
 		skb = kmem_cache_alloc_node(cache, gfp_mask & ~GFP_DMA, node);
 	if (unlikely(!skb))
 		return NULL;
+	skbuff_debugobj_init_and_activate(skb);
 	prefetchw(skb);
 
 	/* We do our best to align skb_shared_info on a separate cache
@@ -459,10 +461,10 @@ struct sk_buff *__alloc_skb(unsigned int
 		fclones->skb2.fclone = SKB_FCLONE_CLONE;
 	}
 
-	skbuff_debugobj_init_and_activate(skb);
 	return skb;
 
 nodata:
+	skbuff_debugobj_init_and_activate(skb);
 	kmem_cache_free(cache, skb);
 	return NULL;
 }
@@ -1598,9 +1600,9 @@ struct sk_buff *skb_clone(struct sk_buff
 		n = kmem_cache_alloc(skbuff_head_cache, gfp_mask);
 		if (!n)
 			return NULL;
+		skbuff_debugobj_init_and_activate(n);
 
 		n->fclone = SKB_FCLONE_UNAVAILABLE;
-		skbuff_debugobj_init_and_activate(n);
 	}
 
 	return __skb_clone(n, skb);
@@ -5488,8 +5490,8 @@ void kfree_skb_partial(struct sk_buff *s
 {
 	if (head_stolen) {
 		skb_release_head_state(skb);
-		kmem_cache_free(skbuff_head_cache, skb);
 		skbuff_debugobj_deactivate(skb);
+		kmem_cache_free(skbuff_head_cache, skb);
 	} else {
 		__kfree_skb(skb);
 	}
--- a/net/core/skbuff_recycle.c
+++ b/net/core/skbuff_recycle.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2014, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2013-2016, The Linux Foundation. All rights reserved.
  *
  * Permission to use, copy, modify, and/or distribute this software for any
  * purpose with or without fee is hereby granted, provided that the above
@@ -43,7 +43,11 @@ inline struct sk_buff *skb_recycler_allo
 
 	h = &get_cpu_var(recycle_list);
 	local_irq_save(flags);
-	skb = __skb_dequeue(h);
+	skb = skb_peek(h);
+	if (skb) {
+		skbuff_debugobj_activate(skb);
+		__skb_unlink(skb, h);
+	}
 #ifdef CONFIG_SKB_RECYCLER_MULTI_CPU
 	if (unlikely(!skb)) {
 		u8 head;
@@ -60,7 +64,11 @@ inline struct sk_buff *skb_recycler_allo
 			glob_recycler.head = head;
 			spin_unlock(&glob_recycler.lock);
 			/* We have refilled the CPU pool - dequeue */
-			skb = __skb_dequeue(h);
+			skb = skb_peek(h);
+			if (skb) {
+				skbuff_debugobj_activate(skb);
+				__skb_unlink(skb, h);
+			}
 		}
 	}
 #endif
@@ -89,7 +97,6 @@ inline struct sk_buff *skb_recycler_allo
 		skb_reset_tail_pointer(skb);
 
 		skb->dev = dev;
-		skbuff_debugobj_activate(skb);
 	}
 
 	return skb;
@@ -172,12 +179,16 @@ inline bool skb_recycler_consume(struct
 static void skb_recycler_free_skb(struct sk_buff_head *list)
 {
 	struct sk_buff *skb = NULL;
+	unsigned long flags;
 
-	while ((skb = skb_dequeue(list)) != NULL) {
-		skb_release_data(skb);
+	spin_lock_irqsave(&list->lock, flags);
+	while ((skb = skb_peek(list)) != NULL) {
 		skbuff_debugobj_activate(skb);
+		__skb_unlink(skb, list);
+		skb_release_data(skb);
 		kfree_skbmem(skb);
 	}
+	spin_unlock_irqrestore(&list->lock, flags);
 }
 
 static int skb_cpu_callback(unsigned int ocpu)
