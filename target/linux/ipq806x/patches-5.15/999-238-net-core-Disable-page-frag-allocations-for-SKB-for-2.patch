From ba2e299ff6f79fba2e9e4bdf524bd79971e50c54 Mon Sep 17 00:00:00 2001
From: Tian Yang <tiany@codeaurora.org>
Date: Tue, 30 Apr 2019 18:43:02 +0530
Subject: [PATCH] net core: Disable page frag allocations for SKB for 256MB
 profile

For low memory profiles such as 256MB, using __alloc_page_frag()
for skb allocations can potentially cause pages to be held up
for longer duration without getting freed by the kernel memory
manageer. This can potentially cause out-of-memory situaions.
This patch disabled page frag based SKB allocations for such
low memory profiles.

Change-Id: Ibc674ad8b46211b8394f0bf7db55366d7210bb01
Signed-off-by: Adil irfan <airfan@codeaurora.org>
Signed-off-by: Kiran Kumar C.S.K <kkumarcs@codeaurora.org>
---
 net/Kconfig       | 8 +++++++-
 net/core/skbuff.c | 7 ++++++-
 2 files changed, 13 insertions(+), 2 deletions(-)

--- a/net/Kconfig
+++ b/net/Kconfig
@@ -341,7 +341,6 @@ config SKB_RECYCLER
 	  routing workloads. It can reduce skbuff freeing or
 	  reallocation overhead.
 
-
 config SKB_RECYCLER_MULTI_CPU
 	bool "Cross-CPU recycling for CPU-locked workloads"
 	depends on SMP && SKB_RECYCLER
@@ -365,6 +364,13 @@ config SKB_RECYCLE_MAX_PREALLOC_SKBS
 	help
 	 Number of SKBs each of 4K size to be preallocated for recycling
 
+config ALLOC_SKB_PAGE_FRAG_DISABLE
+	bool "Disable page fragment based skbuff payload allocations"
+	depends on !SKB_RECYCLER
+	default n
+	help
+	 Disable page fragment based allocations for skbuff payloads.
+
 menu "Network testing"
 
 config NET_PKTGEN
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -489,6 +489,7 @@ struct sk_buff *__netdev_alloc_skb(struc
 	struct page_frag_cache *nc;
 	struct sk_buff *skb;
 	bool pfmemalloc;
+	bool page_frag_alloc_enable = true;
 	void *data;
 
 	unsigned int len = length;
@@ -526,9 +527,13 @@ struct sk_buff *__netdev_alloc_skb(struc
 	/* If requested length is either too small or too big,
 	 * we use kmalloc() for skb->head allocation.
 	 */
+#ifdef CONFIG_ALLOC_SKB_PAGE_FRAG_DISABLE
+	page_frag_alloc_enable = false;
+#endif
 	if (len <= SKB_WITH_OVERHEAD(1024) ||
 	    len > SKB_WITH_OVERHEAD(PAGE_SIZE) ||
-	    (gfp_mask & (__GFP_DIRECT_RECLAIM | GFP_DMA))) {
+	    (gfp_mask & (__GFP_DIRECT_RECLAIM | GFP_DMA)) ||
+	    !page_frag_alloc_enable) {
 		skb = __alloc_skb(len, gfp_mask, SKB_ALLOC_RX, NUMA_NO_NODE);
 		if (!skb)
 			goto skb_fail;
